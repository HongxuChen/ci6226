\section{DBLP Data Extraction}\label{sec:extraction}

The DBLP xml is a huge file that is about 1.7GB. DOM based parsers are not proper to parse it since they consume lots of memories. Instead, we use the Java standard SAX parser. Since it is event based, we have to keep tracking the stats carefully.

Our strategy is to customize our own handler (\textsf{PubHandler}) to track each tag of the xml. When it comes to \textsf{article} or \textsf{inproceedings}, we get its \textsf{key} attribute and mark it interesting.  Then,  whenever we encounter the tags (\textsf{author}, \textsf{title}, \textsf{year}, \textsf{journal}/\textsf{booktitle}, we mark them as the corresponding states, retrieve their content, and finally reset the states at the end of the tag.

Since the one publication might contain several authors, they are stored as a list. Additionally, in some cases, inner tags are used in the xml file, i.e., \verb|<t>|, \verb|<sup>|, \verb|<sub>|, \verb|<tt>|. We simply remove these tags and concatenate them to original text with whitespace. We also filter out some illegal entries that are possibly used by DBLP database internally (for example, those records whose keywords starting with ``dblpnote'' are virtual records that contain no information we are interested in).

Each extracted publication record is stored as a \textsf{Publication} object and used by the concrete Index workers. In order to keep the memory efficient, we make the indexing for each publication the same time as parsing each document. That is to say, when indexing in Project 1, we index each Lucene document once encountering an xml end tag; while for Application 2 in Project 2, we also add the publication title information instantly to document, but the write back operation is delayed. The reason why we apply this approach rather than extract all publications and process them in batch is that we encountered Memory-Out-of-Bound exception by using the other approach. Although this approach has the performance penalty, we believe that it should be a better choice as to scalability.
